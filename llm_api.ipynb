{
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "!pip install -q openai langchain langchain-openai"
      ],
      "metadata": {
        "id": "WMvuN2DDFsa2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import json\n",
        "from openai import OpenAI\n",
        "from langchain_openai import ChatOpenAI\n",
        "from langchain.prompts import ChatPromptTemplate\n",
        "from langchain_core.output_parsers import StrOutputParser, JsonOutputParser\n",
        "from langchain_core.pydantic_v1 import BaseModel, Field"
      ],
      "metadata": {
        "id": "TDfret27Fwux"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "OPENROUTER_API_KEY = \"Your Token Here\"\n",
        "OPENROUTER_BASE_URL = \"https://openrouter.ai/api/v1\"\n",
        "MODEL_NAME = \"moonshotai/kimi-k2:free\""
      ],
      "metadata": {
        "id": "dcuoXIV2IWWi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "client = OpenAI(\n",
        "    base_url=OPENROUTER_BASE_URL,\n",
        "    api_key=OPENROUTER_API_KEY,\n",
        ")\n",
        "\n",
        "llm = ChatOpenAI(\n",
        "    model=MODEL_NAME,\n",
        "    base_url=OPENROUTER_BASE_URL,\n",
        "    api_key=OPENROUTER_API_KEY,\n",
        ")\n",
        "\n",
        "print(\"Successfully initialized clients to use OpenRouter.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PERSi8M6JXrg",
        "outputId": "58c3ab66-915b-442d-90a8-72dbea9daf18"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Successfully initialized clients to use OpenRouter.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def run_example_1_simple_question():\n",
        "    \"\"\"1. Makes a simple API call with a sample question.\"\"\"\n",
        "    print(\"\\n--- Example 1: Simple API Call ---\")\n",
        "    try:\n",
        "        response = client.chat.completions.create(\n",
        "            model=MODEL_NAME,\n",
        "            messages=[\n",
        "                {\"role\": \"system\", \"content\": \"You are a helpful assistant.\"},\n",
        "                {\"role\": \"user\", \"content\": \"What is the largest planet in our solar system?\"}\n",
        "            ]\n",
        "        )\n",
        "        answer = response.choices[0].message.content\n",
        "        print(f\"Question: What is the largest planet in our solar system?\")\n",
        "        print(f\"Answer: {answer}\")\n",
        "    except Exception as e:\n",
        "        print(f\"An error occurred during the API call: {e}\")"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "id": "QpMx10T8FYnM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "run_example_1_simple_question()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oKxHeZIHJ2iW",
        "outputId": "ececb005-a217-41b9-c66e-e3efe62741b6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "--- Example 1: Simple API Call ---\n",
            "Question: What is the largest planet in our solar system?\n",
            "Answer: The largest planet in our solar system is **Jupiter**.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "biography_text = \"\"\"\n",
        "Marie Curie, born on November 7, 1867, was a Polish and naturalized-French physicist and chemist who conducted pioneering research on radioactivity.\n",
        "She was the first woman to win a Nobel Prize, the first person and the only woman to win the Nobel Prize twice, and the only person to win the Nobel Prize in two different scientific fields.\n",
        "Her husband, Pierre Curie, was a co-winner on her first Nobel Prize, making them the first-ever married couple to win the Nobel Prize and launching the Curie family legacy of five Nobel Prizes.\n",
        "She died in 1934 at the age of 66.\n",
        "\"\"\""
      ],
      "metadata": {
        "id": "UxJmDCrZJZK2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def run_example_2_question_with_context():\n",
        "    \"\"\"2. Asks a question based on a provided biography.\"\"\"\n",
        "    print(\"\\n--- Example 2: Question with Provided Context ---\")\n",
        "    try:\n",
        "        response = client.chat.completions.create(\n",
        "            model=MODEL_NAME,\n",
        "            messages=[\n",
        "                {\"role\": \"system\", \"content\": \"You are an expert researcher. Answer the user's question based on the provided text.\"},\n",
        "                {\"role\": \"user\", \"content\": f\"Based on this biography, in what year was Marie Curie born?\\n\\nBiography:\\n{biography_text}\"}\n",
        "            ]\n",
        "        )\n",
        "        answer = response.choices[0].message.content\n",
        "        print(f\"Question: Based on the biography, in what year was Marie Curie born?\")\n",
        "        print(f\"Answer: {answer}\")\n",
        "    except Exception as e:\n",
        "        print(f\"An error occurred during the API call: {e}\")"
      ],
      "metadata": {
        "id": "BwNJMWi0Jl1g"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "run_example_2_question_with_context()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LVDwVFraKPpV",
        "outputId": "ce7cd9c2-a62c-48e6-c502-6703a3706fde"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "--- Example 2: Question with Provided Context ---\n",
            "Question: Based on the biography, in what year was Marie Curie born?\n",
            "Answer: Marie Curie was born in 1867.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def run_example_3_langchain_sequential_pipeline():\n",
        "    \"\"\"3. Uses a LangChain pipeline with successive calls to build a JSON object.\"\"\"\n",
        "    print(\"\\n--- Example 3: LangChain Sequential Pipeline for JSON ---\")\n",
        "    print(\"This method is illustrative but less efficient as it makes multiple calls.\")\n",
        "    try:\n",
        "        prompt_template = ChatPromptTemplate.from_template(\n",
        "            \"Based on the text below, what is the person's {attribute}?\\n\\nText: {context}\"\n",
        "        )\n",
        "        parser = StrOutputParser()\n",
        "\n",
        "        chain_name = prompt_template | llm | parser\n",
        "        chain_birth_year = prompt_template | llm | parser\n",
        "        chain_gender = prompt_template | llm | parser\n",
        "\n",
        "        print(\"Requesting name...\")\n",
        "        name = chain_name.invoke({\"attribute\": \"full name\", \"context\": biography_text})\n",
        "\n",
        "        print(\"Requesting birth year...\")\n",
        "        birth_year_str = chain_birth_year.invoke({\"attribute\": \"birth year\", \"context\": biography_text})\n",
        "        birth_year = int(''.join(filter(str.isdigit, birth_year_str)))\n",
        "\n",
        "\n",
        "        print(\"Requesting gender...\")\n",
        "        gender = chain_gender.invoke({\"attribute\": \"gender\", \"context\": biography_text})\n",
        "\n",
        "        person_json = {\n",
        "            \"name\": name.strip(),\n",
        "            \"birth_year\": birth_year,\n",
        "            \"gender\": gender.strip()\n",
        "        }\n",
        "\n",
        "        print(\"\\nFinal JSON object:\")\n",
        "        print(json.dumps(person_json, indent=2))\n",
        "\n",
        "    except Exception as e:\n",
        "        print(f\"An error occurred during the LangChain pipeline: {e}\")"
      ],
      "metadata": {
        "id": "a7AK_6gdJpUh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "run_example_3_langchain_sequential_pipeline()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tt8_oer0KdBW",
        "outputId": "75f1e030-674a-4d42-efcb-5a04fa5947f3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "--- Example 3: LangChain Sequential Pipeline for JSON ---\n",
            "This method is illustrative but less efficient as it makes multiple calls.\n",
            "Requesting name...\n",
            "Requesting birth year...\n",
            "Requesting gender...\n",
            "\n",
            "Final JSON object:\n",
            "{\n",
            "  \"name\": \"Marie Sk\\u0142odowska Curie (birth name: Maria Salomea Sk\\u0142odowska)\",\n",
            "  \"birth_year\": 1867,\n",
            "  \"gender\": \"The person is female.\"\n",
            "}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def run_example_4_langchain_structured_output():\n",
        "    \"\"\"4. Uses a single call with a JSON output parser for efficient, structured data.\"\"\"\n",
        "    print(\"\\n--- Example 4: LangChain with Structured Output Parser (Single Call) ---\")\n",
        "    print(\"This is the recommended, efficient method for structured data extraction.\")\n",
        "\n",
        "    try:\n",
        "        class PersonInfo(BaseModel):\n",
        "            name: str = Field(description=\"The full name of the person.\")\n",
        "            birth_year: int = Field(description=\"The year the person was born.\")\n",
        "            gender: str = Field(description=\"The gender of the person.\")\n",
        "\n",
        "        parser = JsonOutputParser(pydantic_object=PersonInfo)\n",
        "\n",
        "        prompt = ChatPromptTemplate.from_template(\n",
        "            \"Answer the user query based on the provided context.\\n\"\n",
        "            \"{format_instructions}\\n\"\n",
        "            \"Context: {context}\\n\"\n",
        "            \"Query: Extract the required information for the person described.\"\n",
        "        )\n",
        "\n",
        "        chain = prompt | llm | parser\n",
        "\n",
        "        print(\"Invoking chain to extract structured data in a single call...\")\n",
        "        result_dict = chain.invoke({\n",
        "            \"context\": biography_text,\n",
        "            \"format_instructions\": parser.get_format_instructions()\n",
        "        })\n",
        "\n",
        "        print(\"\\nFinal parsed dictionary:\")\n",
        "        print(result_dict)\n",
        "        print(f\"\\nType of result: {type(result_dict)}\")\n",
        "        print(f\"Accessing data: {result_dict['name']} was born in {result_dict['birth_year']}.\")\n",
        "\n",
        "    except Exception as e:\n",
        "        print(f\"An error occurred during the structured output chain: {e}\")"
      ],
      "metadata": {
        "id": "KPk0jQj0Juy_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "run_example_4_langchain_structured_output()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cvw5UUGRJwo3",
        "outputId": "fb883337-890b-4d53-e4b2-4f5c27f79ffd"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "--- Example 4: LangChain with Structured Output Parser (Single Call) ---\n",
            "This is the recommended, efficient method for structured data extraction.\n",
            "Invoking chain to extract structured data in a single call...\n",
            "\n",
            "Final parsed dictionary:\n",
            "{'name': 'Marie Skłodowska Curie', 'birth_year': 1867, 'gender': 'female'}\n",
            "\n",
            "Type of result: <class 'dict'>\n",
            "Accessing data: Marie Skłodowska Curie was born in 1867.\n"
          ]
        }
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}